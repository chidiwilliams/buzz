# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['buzz', 'buzz.settings', 'buzz.store', 'buzz.widgets']

package_data = \
{'': ['*']}

install_requires = \
['PyQt6==6.4.0',
 'appdirs>=1.4.4,<2.0.0',
 'faster-whisper>=0.4.1,<0.5.0',
 'ffmpeg-python>=0.2.0,<0.3.0',
 'humanize>=4.4.0,<5.0.0',
 'keyring>=23.13.1,<24.0.0',
 'openai-whisper==v20230124',
 'openai>=0.27.1,<0.28.0',
 'platformdirs==3.5.3',
 'sounddevice>=0.4.5,<0.5.0',
 'stable-ts==1.0.2',
 'torch==1.12.1',
 'transformers>=4.24.0,<4.25.0']

setup_kwargs = {
    'name': 'buzz',
    'version': '0.8.3',
    'description': '',
    'long_description': '# Buzz\n\nTranscribe and translate audio offline on your personal computer. Powered by\nOpenAI\'s [Whisper](https://github.com/openai/whisper).\n\n![MIT License](https://img.shields.io/badge/license-MIT-green)\n[![CI](https://github.com/chidiwilliams/buzz/actions/workflows/ci.yml/badge.svg)](https://github.com/chidiwilliams/buzz/actions/workflows/ci.yml)\n[![codecov](https://codecov.io/github/chidiwilliams/buzz/branch/main/graph/badge.svg?token=YJSB8S2VEP)](https://codecov.io/github/chidiwilliams/buzz)\n![GitHub release (latest by date)](https://img.shields.io/github/v/release/chidiwilliams/buzz)\n[![Github all releases](https://img.shields.io/github/downloads/chidiwilliams/buzz/total.svg)](https://GitHub.com/chidiwilliams/buzz/releases/)\n\n<blockquote>\n<p>Buzz is better on the App Store. Get a Mac-native version of Buzz with a cleaner look, audio playback, drag-and-drop import, transcript editing, search, and much more.</p>\n<a href="https://apps.apple.com/us/app/buzz-captions/id6446018936?mt=12&amp;itsct=apps_box_badge&amp;itscg=30200"><img src="https://tools.applemediaservices.com/api/badges/download-on-the-mac-app-store/black/en-us?size=250x83&amp;releaseDate=1679529600" alt="Download on the Mac App Store" /></a>\n</blockquote>\n\n![Buzz](./assets/buzz-banner.jpg)\n\n## Features\n\n- Import audio and video files and export transcripts to TXT, SRT, and\n  VTT ([Demo](https://www.loom.com/share/cf263b099ac3481082bb56d19b7c87fe))\n- Transcription and translation from your computer\'s microphones to text (Resource-intensive and may not be\n  real-time, [Demo](https://www.loom.com/share/564b753eb4d44b55b985b8abd26b55f7))\n- Supports [Whisper](https://github.com/openai/whisper#available-models-and-languages),\n  [Whisper.cpp](https://github.com/ggerganov/whisper.cpp), [Faster Whisper](https://github.com/guillaumekln/faster-whisper),\n  [Whisper-compatible Hugging Face models](https://huggingface.co/models?other=whisper), and\n  the [OpenAI Whisper API](https://platform.openai.com/docs/api-reference/introduction)\n- [Command-Line Interface](#command-line-interface)\n- Available on Mac, Windows, and Linux\n\n## Installation\n\nTo install Buzz, download the [latest version](https://github.com/chidiwilliams/buzz/releases/latest) for your operating\nsystem. Buzz is available on **Mac** (Intel), **Windows**, and **Linux**. (For Apple Silicon, please see the [App Store version](https://apps.apple.com/us/app/buzz-captions/id6446018936?mt=12&itsct=apps_box_badge&itscg=30200).)\n\n### Mac (Intel, macOS 11.7 and later)\n\n- Install via [brew](https://brew.sh/):\n\n  ```shell\n  brew install --cask buzz\n  ```\n\n  Alternatively, download and run the `Buzz-x.y.z.dmg` file.\n\n### Windows (Windows 10 and later)\n\n- Download and run the `Buzz-x.y.z.exe` file.\n\n### Linux (Ubuntu 20.04 and later)\n\n- Install dependencies:\n\n  ```shell\n  sudo apt-get install libportaudio2\n  ```\n\n- Download and extract the `Buzz-x.y.z-unix.tar.gz` file\n\n## How to use\n\n### File import\n\nTo import a file:\n\n- Click Import Media File on the File menu (or the \'+\' icon on the toolbar, or **Command/Ctrl + O**).\n- Choose an audio or video file.\n- Select a task, language, and the model settings.\n- Click Run.\n- When the transcription status shows \'Completed\', double-click on the row (or select the row and click the \'â¤¢\' icon) to\n  open the transcription.\n\n| Field              | Options             | Default | Description                                                                                                                                              |\n| ------------------ | ------------------- | ------- | -------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Export As          | "TXT", "SRT", "VTT" | "TXT"   | Export file format                                                                                                                                       |\n| Word-Level Timings | Off / On            | Off     | If checked, the transcription will generate a separate subtitle line for each word in the audio. Enabled only when "Export As" is set to "SRT" or "VTT". |\n\n(See the [Live Recording section](#live-recording) for more information about the task, language, and quality settings.)\n\n[![Media File Import on Buzz](https://cdn.loom.com/sessions/thumbnails/cf263b099ac3481082bb56d19b7c87fe-with-play.gif)](https://www.loom.com/share/cf263b099ac3481082bb56d19b7c87fe "Media File Import on Buzz")\n\n### Live Recording\n\nTo start a live recording:\n\n- Select a recording task, language, quality, and microphone.\n- Click Record.\n\n> **Note:** Transcribing audio using the default Whisper model is resource-intensive. Consider using the Whisper.cpp\n> Tiny model to get real-time performance.\n\n| Field      | Options                                                                                                                                  | Default                     | Description                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n| ---------- | ---------------------------------------------------------------------------------------------------------------------------------------- | --------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Task       | "Transcribe", "Translate"                                                                                                                | "Transcribe"                | "Transcribe" converts the input audio into text in the selected language, while "Translate" converts it into text in English.                                                                                                                                                                                                                                                                                                                         |\n| Language   | See [Whisper\'s documentation](https://github.com/openai/whisper#available-models-and-languages) for the full list of supported languages | "Detect Language"           | "Detect Language" will try to detect the spoken language in the audio based on the first few seconds. However, selecting a language is recommended (if known) as it will improve transcription quality in many cases.                                                                                                                                                                                                                                 |\n| Quality    | "Very Low", "Low", "Medium", "High"                                                                                                      | "Very Low"                  | The transcription quality determines the Whisper model used for transcription. "Very Low" uses the "tiny" model; "Low" uses the "base" model; "Medium" uses the "small" model; and "High" uses the "medium" model. The larger models produce higher-quality transcriptions, but require more system resources. See [Whisper\'s documentation](https://github.com/openai/whisper#available-models-and-languages) for more information about the models. |\n| Microphone | [Available system microphones]                                                                                                           | [Default system microphone] | Microphone for recording input audio.                                                                                                                                                                                                                                                                                                                                                                                                                 |\n\n[![Live Recording on Buzz](https://cdn.loom.com/sessions/thumbnails/564b753eb4d44b55b985b8abd26b55f7-with-play.gif)](https://www.loom.com/share/564b753eb4d44b55b985b8abd26b55f7 "Live Recording on Buzz")\n\n### Record audio playing from computer\n\nTo record audio playing from an application on your computer, you may install an audio loopback driver (a program that\nlets you create virtual audio devices). The rest of this guide will\nuse [BlackHole](https://github.com/ExistentialAudio/BlackHole) on Mac, but you can use other alternatives for your\noperating system (\nsee [LoopBeAudio](https://nerds.de/en/loopbeaudio.html), [LoopBack](https://rogueamoeba.com/loopback/),\nand [Virtual Audio Cable](https://vac.muzychenko.net/en/)).\n\n1. Install [BlackHole via Homebrew](https://github.com/ExistentialAudio/BlackHole#option-2-install-via-homebrew)\n\n   ```shell\n   brew install blackhole-2ch\n   ```\n\n2. Open Audio MIDI Setup from Spotlight or from `/Applications/Utilities/Audio Midi Setup.app`.\n\n   ![Open Audio MIDI Setup from Spotlight](https://existential.audio/howto/img/spotlight.png)\n\n3. Click the \'+\' icon at the lower left corner and select \'Create Multi-Output Device\'.\n\n   ![Create multi-output device](https://existential.audio/howto/img/createmulti-output.png)\n\n4. Add your default speaker and BlackHole to the multi-output device.\n\n   ![Screenshot of multi-output device](https://existential.audio/howto/img/multi-output.png)\n\n5. Select this multi-output device as your speaker (application or system-wide) to play audio into BlackHole.\n\n6. Open Buzz, select BlackHole as your microphone, and record as before to see transcriptions from the audio playing\n   through BlackHole.\n\n## Command-Line Interface\n\n### `add`\n\nStart a new transcription task\n\nExamples:\n\n```shell\n# Translate two MP3 files from French to English using OpenAI Whisper API\nbuzz add --task translate --language fr --model-type openaiapi /Users/user/Downloads/1b3b03e4-8db5-ea2c-ace5-b71ff32e3304.mp3 /Users/user/Downloads/koaf9083k1lkpsfdi0.mp3\n\n# Transcribe an MP4 using Whisper.cpp "small" model and immediately export to SRT and VTT files\nbuzz add --task transcribe --model-type whispercpp --model-size small --prompt "My initial prompt" --srt --vtt /Users/user/Downloads/buzz/1b3b03e4-8db5-ea2c-ace5-b71ff32e3304.mp4\n```\n\nRun `buzz add --help` to see all available options.\n\n## Build\n\nTo build/run Buzz locally from source, first install the requirements:\n\n1. [Poetry](https://python-poetry.org/docs/#installing-with-the-official-installer)\n\nThen:\n\n1. Clone the repository\n\n   ```shell\n   git clone --recurse-submodules https://github.com/chidiwilliams/buzz\n   ```\n\n2. Install the project dependencies.\n\n   ```shell\n   poetry install\n   ```\n\n3. (Optional) To use Whisper.cpp inference, run:\n\n   ```shell\n   make buzz/whisper_cpp.py\n   ```\n\n4. (Optional) To compile the translations, run:\n\n   ```shell\n   make translation_mo\n   ```\n\n5. Finally, run the app with:\n\n   ```shell\n   poetry run python main.py\n   ```\n\n   Or build with:\n\n   ```shell\n   poetry run pyinstaller --noconfirm Buzz.spec\n   ```\n\n## FAQ\n\n1. **Where are the models stored?**\n\n   The Whisper models are stored in `~/.cache/whisper`. The Whisper.cpp models are stored in `~/Library/Caches/Buzz` (\n   Mac OS), `~/.cache/Buzz` (Unix), or `C:\\Users\\<username>\\AppData\\Local\\Buzz\\Buzz\\Cache` (Windows). The Hugging Face\n   models are stored in `~/.cache/huggingface/hub`.\n\n2. **What can I try if the transcription runs too slowly?**\n\n   Try using a lower Whisper model size or using a Whisper.cpp model.\n\n## Credits\n\n- SVG Icons: [Google Fonts Material Symbols](https://fonts.google.com/icons)\n',
    'author': 'Chidi Williams',
    'author_email': 'williamschidi1@gmail.com',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'None',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=3.9.13,<3.11',
}
from build import *
build(setup_kwargs)

setup(**setup_kwargs)
